{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/villifCoder559/VGGFaceFeatures_PCA/blob/main/VGGFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61gnvBUPhJNr"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -Uqq ipdb\n",
        "import ipdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjaRyJjosHEd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install faiss-cpu --no-cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvE2z802PlYv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/rcmalli/keras-vggface.git\n",
        "!pip install tensorflow keras_applications\n",
        "!pip install layer_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4_W4a6SCKMr"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install keras==2.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPyZ0drGU3D5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import keras\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from skimage.transform import resize\n",
        "import faiss\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy0QwabIes5O"
      },
      "source": [
        "<h1>Balancing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IddmW05E2Zyp"
      },
      "outputs": [],
      "source": [
        "def init_balanced_dataset(lfw_people,balanced_dataset=True):\n",
        "  np.random.seed(42)\n",
        "  data=lfw_people.images\n",
        "  target=lfw_people.target\n",
        "  index_list,nr_elements_per_class=np.unique(target,return_counts=True)\n",
        "  min_elements=min(nr_elements_per_class)\n",
        "  balanced_data=[]\n",
        "  balanced_target=[]\n",
        "  if balanced_dataset:\n",
        "    for s_class in index_list:\n",
        "      list_indices = np.argwhere(target == s_class).reshape(-1)\n",
        "      choices = np.random.choice(list_indices, min_elements, replace = False)\n",
        "      balanced_target.append(np.full(min_elements,s_class))\n",
        "      balanced_data.append(data[choices])\n",
        "    balanced_data=np.array(balanced_data)\n",
        "    balanced_target=np.array(balanced_target)\n",
        "    balanced_data=balanced_data.reshape(balanced_data.shape[0]*balanced_data.shape[1],balanced_data.shape[2],balanced_data.shape[3],balanced_data.shape[4])\n",
        "    balanced_target=balanced_target.reshape(-1)\n",
        "    print('balancedData',balanced_data.shape)\n",
        "    print('balancedTarget',balanced_target.shape)\n",
        "    print()\n",
        "  else:\n",
        "    balanced_data=data\n",
        "    balanced_target=target\n",
        "    print('balancedData',balanced_data.shape)\n",
        "    print('balancedTarget',balanced_target.shape)\n",
        "  return balanced_data,balanced_target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glcX5CjKiDI2"
      },
      "source": [
        "<h1>Image normalization and standardization and Extract features</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmuLa6h2k5zX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "def compute_features(balanced_data,balanced_target,use_VGGface=True,random_state=2,std_dataset=True):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(balanced_data, balanced_target, test_size=0.2, random_state=random_state)\n",
        "\n",
        "  image_samples_train=np.copy(X_train)\n",
        "  if std_dataset:\n",
        "    image_samples_train=np.array([cv2.resize(img,(224,224)) for img in image_samples_train])\n",
        "    image_samples_train[:,:,:,0]=(image_samples_train[:,:,:,0]-np.mean(X_train[:,:,:,0]))/(np.std(X_train[:,:,:,0]))\n",
        "    image_samples_train[:,:,:,1]=(image_samples_train[:,:,:,1]-np.mean(X_train[:,:,:,1]))/(np.std(X_train[:,:,:,1]))\n",
        "    image_samples_train[:,:,:,2]=(image_samples_train[:,:,:,2]-np.mean(X_train[:,:,:,2]))/(np.std(X_train[:,:,:,2]))\n",
        "\n",
        "  image_samples_test=np.copy(X_test)\n",
        "  if(std_dataset):\n",
        "    image_samples_test=np.array([cv2.resize(img,(224,224)) for img in image_samples_test])\n",
        "    image_samples_test[:,:,:,0]=(image_samples_test[:,:,:,0]-np.mean(X_train[:,:,:,0]))/(np.std(X_train[:,:,:,0]))\n",
        "    image_samples_test[:,:,:,1]=(image_samples_test[:,:,:,1]-np.mean(X_train[:,:,:,1]))/(np.std(X_train[:,:,:,1]))\n",
        "    image_samples_test[:,:,:,2]=(image_samples_test[:,:,:,2]-np.mean(X_train[:,:,:,2]))/(np.std(X_train[:,:,:,2]))\n",
        "  if use_VGGface:\n",
        "    if tf.config.list_physical_devices('GPU'):\n",
        "      vggface = VGGFace(model='vgg16',include_top=False,input_shape=(image_samples_train.shape[1],image_samples_train.shape[2],image_samples_train.shape[3]))\n",
        "      result_train=vggface.predict(image_samples_train)\n",
        "      result_test=vggface.predict(image_samples_test)\n",
        "      print('GPU available')\n",
        "    else:\n",
        "      drive.mount('/content/drive')\n",
        "      drive_path = '/content/drive/MyDrive/'\n",
        "      result_train=np.load(os.path.join(drive_path, 'VGGFace_features_faces_norm_std_train.npy'),allow_pickle=True)\n",
        "      result_test=np.load(os.path.join(drive_path, 'VGGFace_features_faces_norm_std_test.npy'),allow_pickle=True)\n",
        "      print('GPU not available. Getting features from local BALANCED dataset (train_test_split with random_state=2)...')\n",
        "  else:\n",
        "    result_train=image_samples_train\n",
        "    result_test=image_samples_test\n",
        "  return result_train,result_test,y_test,y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LscqwWAMkmVU"
      },
      "source": [
        "<h1>Save/load features from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFvqiw-31-z5"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# import os\n",
        "# drive.mount('/content/drive')\n",
        "# drive_path = '/content/drive/MyDrive/'\n",
        "# np.save(os.path.join(drive_path, 'VGGFace_features_faces_norm_std_train.npy'), original_result_train)\n",
        "# np.save(os.path.join(drive_path, 'VGGFace_features_faces_norm_std_test.npy'), original_result_test)\n",
        "# np.save(os.path.join(drive_path, 'VGGFace_features_faces_train.npy'), original_result_train)\n",
        "# np.save(os.path.join(drive_path, 'VGGFace_features_faces_test.npy'), original_result_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylhbR17i2uDM"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# import os\n",
        "# drive.mount('/content/drive')\n",
        "# drive_path = '/content/drive/MyDrive/'\n",
        "# result_train_vgg=np.load(os.path.join(drive_path, 'VGGFace_features_faces_norm_std_train.npy'),allow_pickle=True)\n",
        "# result_test_vgg=np.load(os.path.join(drive_path, 'VGGFace_features_faces_norm_std_test.npy'),allow_pickle=True)\n",
        "# result_train_vgg=np.load(os.path.join(drive_path, 'VGGFace_features_faces_train.npy'),allow_pickle=True)\n",
        "# result_test_vgg=np.load(os.path.join(drive_path, 'VGGFace_features_faces_test.npy'),allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1RKwLuhXeDy"
      },
      "outputs": [],
      "source": [
        "#create reduction (if n_components is negative it means to remove the first n_components instead of lasts)\n",
        "def create_test_reduction(n_components,result_train,type_index='FlatL2',fixed_components=30):\n",
        "  if type_index not in ['FlatL2', 'FlatIP']:\n",
        "        raise ValueError(\"Type must be 'FlatL2' or 'FlatIP'\")\n",
        "  features_reducted=result_train.reshape(result_train.shape[0],-1)\n",
        "  if n_components > 0:\n",
        "    tmp_PCA=PCA(n_components=n_components)\n",
        "    features_reducted=np.ascontiguousarray(tmp_PCA.fit_transform(features_reducted))\n",
        "  else:\n",
        "    tmp_PCA=PCA(n_components=fixed_components).fit(features_reducted)\n",
        "    features_reducted=custom_reduction(tmp_PCA,result_train,n_components)\n",
        "  faiss.normalize_L2(features_reducted)\n",
        "#   # Get explained variance\n",
        "#   explained_variance_ratio = tmp_PCA.explained_variance_ratio_\n",
        "\n",
        "#   # Calculate cumulative explained variance\n",
        "#   cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "#   # Individual explained variance plot\n",
        "#   plt.figure(figsize=(8, 6))\n",
        "#   plt.bar(range(len(explained_variance_ratio)), explained_variance_ratio)\n",
        "#   plt.xlabel('Principal Component')\n",
        "#   plt.ylabel('Explained Variance Ratio')\n",
        "#   plt.title('Individual Explained Variance per Component')\n",
        "\n",
        "#   # Add vertical lines at specific points\n",
        "#   plt.axvline(x=20, color='r', linestyle='--', label='X=20')\n",
        "#   plt.axvline(x=50, color='g', linestyle='--', label='X=50')\n",
        "#   plt.axvline(x=100, color='b', linestyle='--', label='X=100')\n",
        "#   plt.axvline(x=396, color='k', linestyle='--', label='X=396')  # Assuming the maximum component is 396\n",
        "#   plt.legend()\n",
        "\n",
        "#   # Cumulative explained variance plot\n",
        "#   plt.figure(figsize=(8, 6))\n",
        "#   plt.plot(range(len(cumulative_explained_variance_ratio)), cumulative_explained_variance_ratio,\n",
        "#             marker='o', linestyle='--')\n",
        "#   plt.xlabel('Principal Component')\n",
        "#   plt.ylabel('Cumulative Explained Variance Ratio')\n",
        "#   plt.title('Cumulative Explained Variance')\n",
        "\n",
        "#   # Add vertical lines at specific points (optional, adjust for cumulative plot if needed)\n",
        "#   plt.axvline(x=20, color='r', linestyle='--', label='X=20')\n",
        "#   plt.axvline(x=50, color='g', linestyle='--', label='X=50')\n",
        "#   plt.axvline(x=100, color='b', linestyle='--', label='X=100')\n",
        "#   plt.axvline(x=396, color='k', linestyle='--', label='X=396')\n",
        "#   plt.legend()\n",
        "#   plt.show()\n",
        "  if type_index=='FlatIP':\n",
        "    return tmp_PCA,features_reducted,faiss.IndexFlatIP(features_reducted.shape[1])\n",
        "  else:\n",
        "    return tmp_PCA,features_reducted,faiss.IndexFlatL2(features_reducted.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c8Y3ky9fZSf"
      },
      "outputs": [],
      "source": [
        "def custom_reduction(pca,result_train,start_index):\n",
        "  transformed_results = []\n",
        "  for element in result_train:\n",
        "    test = element.reshape(1, -1)\n",
        "    # Apply PCA transformation\n",
        "    transformed_result = np.dot(test - pca.mean_, pca.components_[(-start_index):].T)\n",
        "    transformed_results.append(transformed_result)\n",
        "  return np.array(transformed_results).reshape(result_train.shape[0],pca.components_.shape[0]+start_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdv6dHVIfMTn"
      },
      "source": [
        "<h1>Create Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcs4ZeZcJX4G"
      },
      "outputs": [],
      "source": [
        "def create_test(list_n_components,fixed_components,result_train_vgg):\n",
        "  index_type='FlatIP' # FlatIP or FlatL2\n",
        "  print('Fixed_components=',fixed_components)\n",
        "  pca_objs=[]\n",
        "  features_objs=[]\n",
        "  index_faiss_objs=[]\n",
        "  for n_components in list_n_components:\n",
        "    if n_components>0:\n",
        "      pca,features,index=create_test_reduction(n_components,result_train_vgg,index_type)\n",
        "      pca_objs.append(pca)\n",
        "      features_objs.append(features)\n",
        "      index_faiss_objs.append(index)\n",
        "    else:\n",
        "      if(n_components<0):\n",
        "        pca,features,index=create_test_reduction(n_components,result_train_vgg,index_type,fixed_components)\n",
        "        pca_objs.append(pca)\n",
        "        features_objs.append(features)\n",
        "        index_faiss_objs.append(index)\n",
        "      else: # dummy PCA\n",
        "        pca_objs.append(PCA())\n",
        "        res_train_norm=np.copy(result_train_vgg.reshape(result_train_vgg.shape[0],-1))\n",
        "        faiss.normalize_L2(res_train_norm)\n",
        "        features_objs.append(res_train_norm)\n",
        "        if index_type=='FlatIP':\n",
        "          index_faiss_objs.append(faiss.IndexFlatIP(res_train_norm.shape[1]))\n",
        "        else:\n",
        "          index_faiss_objs.append(faiss.IndexFlatL2(res_train_norm.shape[1]))\n",
        "  #add vectors to index\n",
        "  count=0\n",
        "  for index in index_faiss_objs:\n",
        "    # print(features_objs[count].shape)\n",
        "    index.add(features_objs[count])\n",
        "    count=count+1\n",
        "  return pca_objs,features_objs,index_faiss_objs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzd9K7Oml09B"
      },
      "outputs": [],
      "source": [
        "def compute_precision_recall(ground_truth,target,index,top_k,reduced_vector,train_elements_nr):\n",
        "  TP=-1\n",
        "  reduced_vector=np.ascontiguousarray(reduced_vector.reshape(1, -1))\n",
        "  # print(reduced_vector.shape)\n",
        "  _,retrived_elements=index.search(reduced_vector, train_elements_nr)\n",
        "  retrived_targets_id=ground_truth[retrived_elements]==target\n",
        "  # print(retrived_elements)\n",
        "  indices = np.where(retrived_targets_id.reshape(-1))[0]\n",
        "  if(top_k>len(indices)):\n",
        "    # print('Face nr.',target,'max elements:',len(indices)-1,'(NOT',str(top_k)+')')\n",
        "    top_k=len(indices)\n",
        "  stop=indices[top_k-1]+1\n",
        "  TP=top_k\n",
        "  total_samples=np.sum(ground_truth==target)\n",
        "  FP=stop-TP\n",
        "  FN=total_samples-TP\n",
        "  precision=0\n",
        "  if TP+FP!=0:\n",
        "    precision=TP/(TP+FP)\n",
        "  recall=TP/((TP+FN))\n",
        "  return precision,recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdGoaALBohJf"
      },
      "outputs": [],
      "source": [
        "def predict(ground_truth_train,ground_truth_test,index_faiss_objs,test_vectors,list_n_components,train_elements_nr=9):\n",
        "  i=0\n",
        "  j=0\n",
        "  test_vectors=test_vectors.reshape(test_vectors.shape[0],-1)\n",
        "  nr_labels=np.unique(y_train).shape[0]\n",
        "  result=[]\n",
        "  list_results=[]\n",
        "\n",
        "  for index in index_faiss_objs:\n",
        "      # start=time.time()\n",
        "      for vector in test_vectors:\n",
        "        # print(list_n_components[i])\n",
        "        if list_n_components[i] > 0:\n",
        "          reduced_vector=(vector.reshape(1,-1)-pca_objs[i].mean_)@pca_objs[i].components_.T\n",
        "        else:\n",
        "          if list_n_components[i] < 0:\n",
        "            reduced_vector=(vector.reshape(1,-1)-pca_objs[i].mean_)@pca_objs[i].components_[-list_n_components[i]:].T\n",
        "          else:\n",
        "            reduced_vector=vector\n",
        "            reduced_vector=np.reshape(reduced_vector,(1,reduced_vector.shape[0]))\n",
        "        reduced_vector=reduced_vector/np.linalg.norm(reduced_vector)\n",
        "        # ipdb.set_trace()\n",
        "        distances,retrived_elements=index.search(reduced_vector, train_elements_nr)\n",
        "        sum_per_class=[np.sum(ground_truth_train[retrived_elements]==i) for i in range(nr_labels)]\n",
        "        max_indices = np.where(sum_per_class == np.max(sum_per_class))[0]\n",
        "        if len(max_indices) > 1:  # If multiple classes have the same sum\n",
        "          index_vct=[(ground_truth_train[retrived_elements]==i) for i in (max_indices)]\n",
        "          dist=[np.sum(distances[vector]) for vector in index_vct]\n",
        "          # if(index.__class__.__name__ == 'IndexFlatIP'): USE IN CASE VECTORS AREN'T NORMALIZED -> L2_dist != IP_dist\n",
        "          max_index=np.argmax(dist)\n",
        "          best=max_indices[max_index]\n",
        "          # else:\n",
        "          #   min_index=np.argmin(dist)\n",
        "          #   best=max_indices[min_index]\n",
        "          # ipdb.set_trace()\n",
        "        else:\n",
        "          best = max_indices[0]\n",
        "        result.append(best)\n",
        "        j+=1\n",
        "      j=0\n",
        "      i=i+1\n",
        "      result=np.array(result)\n",
        "      accuracy=np.sum(result==ground_truth_test)/result.shape[0]\n",
        "      list_results.append(accuracy)\n",
        "      result=[]\n",
        "  return list_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1QvvIAafYHQ"
      },
      "source": [
        "<h1>Compute Precision-recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpBTT2YzqBTP"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def compute_all_precision_recall(list_top_elements,list_n_components,index_faiss_objs,pca_objs,y_train,y_test,result_test_vgg,result_train):\n",
        "  # list_top_elements=[5,10,20,100]\n",
        "  i=0\n",
        "  j=0\n",
        "  k=0\n",
        "  precision_results=[]\n",
        "  recall_results=[]\n",
        "  name_results=[]\n",
        "  list_precision_results=[]\n",
        "  list_recall_results=[]\n",
        "  # reduced_vector_list=[]\n",
        "  test_vectors=result_test_vgg.reshape(result_test_vgg.shape[0],-1)\n",
        "  for top_k in list_top_elements:\n",
        "    for index in index_faiss_objs:\n",
        "      # start=time.time()\n",
        "      for vector in test_vectors:\n",
        "        if list_n_components[i] > 0:\n",
        "          reduced_vector=(vector.reshape(1,-1)-pca_objs[i].mean_)@pca_objs[i].components_.T\n",
        "        else:\n",
        "          if list_n_components[i] < 0:\n",
        "            reduced_vector=(vector.reshape(1,-1)-pca_objs[i].mean_)@pca_objs[i].components_[-list_n_components[i]:].T\n",
        "          else:\n",
        "            reduced_vector=np.array(vector)\n",
        "        reduced_vector=reduced_vector/np.linalg.norm(reduced_vector)\n",
        "        # reduced_vector_list.append(reduced_vector)\n",
        "        # predict(y_train,index,reduced_vector,9)\n",
        "        precision,recall=compute_precision_recall(y_train,y_test[j],index,top_k,reduced_vector,result_train.shape[0])\n",
        "        name_results.append(y_test[j])\n",
        "        precision_results.append(precision)\n",
        "        recall_results.append(recall)\n",
        "        j=j+1\n",
        "      j=0\n",
        "      i=i+1\n",
        "    i=0\n",
        "      # tmp=time.time()-start\n",
        "  recall_results=np.array(recall_results).reshape(len(list_top_elements),len(index_faiss_objs),test_vectors.shape[0])\n",
        "  precision_results=np.array(precision_results).reshape(len(list_top_elements),len(index_faiss_objs),test_vectors.shape[0])\n",
        "  name_results=np.array(name_results).reshape(len(list_top_elements),len(index_faiss_objs),test_vectors.shape[0])\n",
        "  return recall_results,precision_results,name_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh9hY2qno4n4"
      },
      "outputs": [],
      "source": [
        "def create_DataFrame(id_labels,selected_name_result,selected_precision_result,selected_recall_result,normalization_factors,index_faiss_n_components,list_n_components,index_selected_top_k_retrival):\n",
        "  str_top_k=str(list_top_elements[index_selected_top_k_retrival])\n",
        "  text=''\n",
        "  index_type=''\n",
        "  precision_vector=np.bincount(selected_name_result,weights=selected_precision_result)/normalization_factors\n",
        "  recall_vector=np.bincount(selected_name_result,weights=selected_recall_result)/normalization_factors\n",
        "  # F1_vector=2*(precision_vector*recall_vector)/(precision_vector+recall_vector)\n",
        "  if index_faiss_objs[index_faiss_n_components].__class__.__name__ == 'IndexFlatIP':\n",
        "    index_type='(IP)'\n",
        "  else:\n",
        "    index_type='(L2)'\n",
        "  if list_n_components[index_faiss_n_components]<0:\n",
        "    text='/'+str(fixed_components)\n",
        "  df = pd.DataFrame({\n",
        "    \"Faces\":id_labels,\n",
        "    # (\"F\"+index_type+\"@\"+str_top_k+'_'+str(list_n_components[index_faiss_n_components])+text):F1_vector        # F1\n",
        "    (\"P\"+index_type+\"@\"+str_top_k+'_'+str(list_n_components[index_faiss_n_components])+text):precision_vector,  # Precision\n",
        "    # (\"R@\"+str_top_k+'_'+str(list_n_components[index_faiss_n_components])):recall_vector,                      # Recall\n",
        "  })\n",
        "  # Calculate the averages of each column\n",
        "  avg_row = df.mean(axis=0)\n",
        "  avg_row[\"Faces\"] = \"Average\"\n",
        "  # Append the average row to the DataFrame\n",
        "  # df = pd.concat([df,avg_row],ignore_index=True)\n",
        "  df = df.append(avg_row, ignore_index=True)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wccn9Ttfn_LI"
      },
      "outputs": [],
      "source": [
        "def create_list_dataframe(precision_results,name_results,recall_results,list_n_components,y_test,list_top_elements):\n",
        "  df_list=[]\n",
        "  # avg_precision=[]\n",
        "  for i in range(precision_results.shape[0]):\n",
        "    for j in range(precision_results.shape[1]):\n",
        "      selected_name_result = name_results[i][j]\n",
        "      selected_recall_result = recall_results[i][j]\n",
        "      selected_precision_result = precision_results[i][j]\n",
        "      # avg_precision.append(np.mean(selected_precision_result))\n",
        "      id_labels,normalization_factors = np.unique(y_test,return_counts=True)\n",
        "      df=create_DataFrame(id_labels,selected_name_result,selected_precision_result,selected_recall_result,normalization_factors,j,list_n_components,i)\n",
        "      df_list.append(df)\n",
        "  # avg_precision=np.array(avg_precision).reshape(len(list_top_elements),len(list_n_components))\n",
        "  return df_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Prq_Z7xFASMq"
      },
      "source": [
        "F1 Score all retrived<br>\n",
        "P(IP)@1000_0    -> F-Score(distance_InnerProduct)@all_elements_noPCAReduction<br>\n",
        "P(IP)@1000_200  ->F-Score(distance_InnerProduct)@all_elements_PCA_200_Components<br>\n",
        "P(IP)@1000_-2/25-> F-Score(Distance_InnerProduct)@W/h first 2 componets out of 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTYR-O2eVwTO"
      },
      "outputs": [],
      "source": [
        "def merge_dataframe(list_top_elements,df_list,drop_faces_col=True):\n",
        "  merged_df_list=[]\n",
        "  count=0\n",
        "  for pick_top_k in list_top_elements:\n",
        "    merged_df=df_list[count]\n",
        "    for i in range(count+1,count+int(len(df_list)/len(list_top_elements))):\n",
        "      merged_df=pd.merge(merged_df,df_list[i])\n",
        "    if drop_faces_col:\n",
        "      merged_df_list.append(merged_df.drop(columns=['Faces']).style.highlight_min(color = 'red', axis = 1).highlight_max(color = 'green', axis = 1))\n",
        "    else:\n",
        "      merged_df_list.append(merged_df)\n",
        "    count+=int(len(df_list)/len(list_top_elements))\n",
        "  return merged_df_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jww-7Tt_oPKq"
      },
      "outputs": [],
      "source": [
        "def compute_fisher(pca_objs,list_n_components,result_train,result_test,y_train):\n",
        "  accuracy_results=[]\n",
        "  count=0\n",
        "  # for n_components in list_n_components:\n",
        "  for pca in pca_objs:\n",
        "    print('PCA components',list_n_components[count])\n",
        "    eigenface_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
        "    if list_n_components[count]>0:\n",
        "      train=pca.fit_transform(result_train.reshape(result_train.shape[0],-1))\n",
        "    else:\n",
        "      train=result_train.reshape(result_train.shape[0],-1)\n",
        "    eigenface_recognizer.train(train, np.array(y_train))\n",
        "    correct = 0\n",
        "    if list_n_components[count]>0:\n",
        "      test=pca.transform(result_test.reshape(result_test.shape[0],-1))\n",
        "    else:\n",
        "      test=result_test.reshape(result_test.shape[0],-1)\n",
        "    total = len(test)\n",
        "    for i in range(total):\n",
        "        label, confidence = eigenface_recognizer.predict(test[i])\n",
        "        if label == y_test[i]:\n",
        "            correct += 1\n",
        "    accuracy = correct / total\n",
        "    accuracy_results.append(accuracy)\n",
        "    # print(f\"Accuracy: {accuracy}%\")\n",
        "    # print()\n",
        "  return np.array(accuracy_results).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvG4aRieMRTU"
      },
      "outputs": [],
      "source": [
        "lfw_people = fetch_lfw_people(min_faces_per_person=30, resize=2.4,color=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2arm7SQrTGvf",
        "outputId": "3c901a67-3f55-437a-b6ce-cb1aa7dc0b8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(lfw_people.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLjbpx_EG3tG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72cd9007-326f-4a45-9ff0-1a6de7979257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "balancedData (2370, 300, 225, 3)\n",
            "balancedTarget (2370,)\n",
            "60/60 [==============================] - 16s 151ms/step\n",
            "15/15 [==============================] - 7s 511ms/step\n",
            "GPU available\n",
            "Fixed_components= 20\n",
            "random_state 7 time -> -81.56978964805603\n",
            "60/60 [==============================] - 7s 122ms/step\n",
            "15/15 [==============================] - 2s 125ms/step\n",
            "GPU available\n",
            "Fixed_components= 20\n",
            "random_state 8 time -> -58.70343232154846\n",
            "60/60 [==============================] - 8s 125ms/step\n",
            "15/15 [==============================] - 2s 124ms/step\n",
            "GPU available\n",
            "Fixed_components= 20\n",
            "random_state 9 time -> -56.04190444946289\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "list_top_elements = [5]\n",
        "list_n_components =[0,20,50,100,396] # 0 -> No PCA reduction\n",
        "fixed_components_list = [20]\n",
        "random_state_list= range(7,10)\n",
        "predictions_vgg=[]\n",
        "predictions_fisher=[]\n",
        "list_precision_results=[]\n",
        "make_prediction=True\n",
        "balanced_data,balanced_target=init_balanced_dataset(lfw_people,balanced_dataset=False)\n",
        "for random_state in random_state_list:\n",
        "  start=time.time()\n",
        "  for fixed_components in fixed_components_list:\n",
        "    result_train,result_test,y_test,y_train=compute_features(balanced_data,balanced_target,use_VGGface=True,random_state=random_state,std_dataset=True)\n",
        "    pca_objs, features_objs, index_faiss_objs = create_test(list_n_components,fixed_components,result_train)\n",
        "    if make_prediction:\n",
        "      predictions_vgg.append(predict(y_train,y_test,index_faiss_objs,result_test,list_n_components))\n",
        "      # predictions_fisher.append(compute_fisher(pca_objs,list_n_components,result_train,result_test,y_train))\n",
        "    else:\n",
        "      recall_results, precision_results, name_results = compute_all_precision_recall(list_top_elements,list_n_components,index_faiss_objs,pca_objs,y_train,y_test,result_test,result_train)\n",
        "      df_list=create_list_dataframe(precision_results,name_results,recall_results,list_n_components,y_test,list_top_elements)\n",
        "      merged_df_list=merge_dataframe(list_top_elements,df_list,drop_faces_col=False)\n",
        "      list_precision_results.append(merged_df_list)\n",
        "  print('random_state '+str(random_state)+' time -> '+str(start-time.time()))\n",
        "if make_prediction:\n",
        "  predictions_vgg=np.array(predictions_vgg)\n",
        "list_precision_results = np.array(list_precision_results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_vgg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn1XxFYqwmxB",
        "outputId": "4ca345d1-6eda-4b1c-fb5e-b1c435da3b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.98523207, 0.94725738, 0.94936709, 0.9556962 , 0.97046414],\n",
              "       [0.97679325, 0.92827004, 0.95147679, 0.9535865 , 0.96413502],\n",
              "       [0.96624473, 0.907173  , 0.93881857, 0.94936709, 0.95147679]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix=np.array(([[0.97046414, 0.92405063, 0.94514768, 0.95991561, 0.95991561],\n",
        "       [0.98312236, 0.94936709, 0.96624473, 0.97890295, 0.98312236],\n",
        "\t   [0.97890295, 0.92616034, 0.9535865 , 0.95991561, 0.96202532],\n",
        "       [0.97890295, 0.91772152, 0.94725738, 0.96202532, 0.96413502],\n",
        "\t   [0.97890295, 0.93248945, 0.9535865 , 0.96835443, 0.97046414],\n",
        "       [0.98734177, 0.94514768, 0.9556962 , 0.96835443, 0.96835443],\n",
        "\t   [0.98523207, 0.94725738, 0.94936709, 0.9556962 , 0.97046414],\n",
        "       [0.97679325, 0.92827004, 0.95147679, 0.9535865 , 0.96413502],\n",
        "       [0.96624473, 0.907173  , 0.93881857, 0.94936709, 0.95147679]\n",
        "\t   ]))\n",
        "np.mean(matrix,axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM0C3RGcBIlp",
        "outputId": "ee072176-cbd7-482e-9f64-6b28cffb6bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97843413, 0.93084857, 0.95124238, 0.9617909 , 0.96601031])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean=np.mean(np.array(list_precision_results)[:,:,:,1:],axis=(0))\n",
        "t=np.array(list_precision_results)[:,:,:,1:].astype(np.float64)\n",
        "std=np.std(t,axis=(0))\n",
        "obj={}\n",
        "for i in range(len(list_top_elements)):\n",
        "  # obj['mean_top_'+str(list_top_elements[i])]=[]\n",
        "  # obj['std_top_'+str(list_top_elements[i])]=[]\n",
        "  for j in range(len(list_n_components)):\n",
        "    key_mean = 'mean_top_' + str(list_top_elements[i]) + '|cmp_' + str(list_n_components[j])\n",
        "    key_std = 'std_top_' + str(list_top_elements[i]) + '|cmp_' + str(list_n_components[j])\n",
        "    if not isinstance(obj.get(key_mean), list):\n",
        "        obj[key_mean] = []\n",
        "    obj[key_mean].append(mean[i,:,j])\n",
        "    if not isinstance(obj.get(key_std), list):\n",
        "        obj[key_std] = []\n",
        "    obj[key_std].append(std[i,:,j])"
      ],
      "metadata": {
        "id": "9PPcZyAECYgZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "a716a56b-5b79-40f8-ceff-1e8fd6b1739b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "too many indices for array: array is 1-dimensional, but 4 were indexed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3b344e32bd0c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_precision_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_precision_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_top_elements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 4 were indexed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test if it works with len(fixed_components_list)=1\n",
        "#NEGATIVE elements with len(fixed_component_list)>1\n",
        "tst=np.array(list_precision_results).reshape(len(random_state_list),len(fixed_components_list),len(list_top_elements),10,-1)\n",
        "mean=np.mean(tst[:,:,:,:,1:],axis=(0))\n",
        "t=tst[:,:,:,:,1:].astype(np.float64)\n",
        "std=np.std(t,axis=(0))\n",
        "obj={}\n",
        "for i in range(len(fixed_components_list)):\n",
        "  # obj['mean_top_'+str(list_top_elements[i])]=[]\n",
        "  # obj['std_top_'+str(list_top_elements[i])]=[]\n",
        "  for j in range(len(list_top_elements)):\n",
        "    for k in range(len(list_n_components)):\n",
        "      key_mean = 'mean_top_' + str(list_top_elements[j]) + '|cmp_' + str(list_n_components[k])+'/'+str(fixed_components_list[i])\n",
        "      key_std = 'std_top_' + str(list_top_elements[j]) + '|cmp_' + str(list_n_components[k])+'/'+str(fixed_components_list[i])\n",
        "      if not isinstance(obj.get(key_mean), list):\n",
        "          obj[key_mean] = []\n",
        "      obj[key_mean].append(mean[i,j,:,k])\n",
        "      if not isinstance(obj.get(key_std), list):\n",
        "          obj[key_std] = []\n",
        "      obj[key_std].append(std[i,j,:,k])"
      ],
      "metadata": {
        "id": "_Uwe-PrqPAVd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "2f837a61-fb48-4b79-a6b6-850cdba14d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 0 is out of bounds for axis 3 with size 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-0ce23ccf973c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_mean\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_mean\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_std\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 3 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7l8ehisV3up"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pickle\n",
        "drive.mount('/content/drive')\n",
        "drive_path = '/content/drive/MyDrive/'\n",
        "# Serialize and save the object to a file\n",
        "with open('/content/drive/My Drive/obj_no_std_negative.pkl', 'wb') as f:\n",
        "    pickle.dump(obj, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pickle\n",
        "drive.mount('/content/drive')\n",
        "drive_path = '/content/drive/MyDrive/'\n",
        "with open('/content/drive/My Drive/obj_no_std_negative.pkl', 'rb') as f:\n",
        "    obj_no_std = pickle.load(f)\n",
        "with open('/content/drive/My Drive/obj_std_negative.pkl', 'rb') as f:\n",
        "    obj_std = pickle.load(f)"
      ],
      "metadata": {
        "id": "ZMHfRMtZ_H5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hn034EVIO95V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "a3247b99-5282-4265-b453-59c8b40d09f9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'merged_df_list' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-698af4a431a0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged_df_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'merged_df_list' is not defined"
          ]
        }
      ],
      "source": [
        "merged_df_list[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WAhvdLPPAC9"
      },
      "outputs": [],
      "source": [
        "merged_df_list[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNabDmJMPBnh"
      },
      "outputs": [],
      "source": [
        "merged_df_list[3]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}